{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/pcadmin/Desktop/project/AILogistics/mosaic-ai-client/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pcadmin/Desktop/project/AILogistics/mosaic-ai-client/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pcadmin/Desktop/project/AILogistics/mosaic-ai-client/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pcadmin/Desktop/project/AILogistics/mosaic-ai-client/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pcadmin/Desktop/project/AILogistics/mosaic-ai-client/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pcadmin/Desktop/project/AILogistics/mosaic-ai-client/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/pcadmin/Desktop/project/AILogistics/mosaic-ai-client/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pcadmin/Desktop/project/AILogistics/mosaic-ai-client/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pcadmin/Desktop/project/AILogistics/mosaic-ai-client/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pcadmin/Desktop/project/AILogistics/mosaic-ai-client/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pcadmin/Desktop/project/AILogistics/mosaic-ai-client/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pcadmin/Desktop/project/AILogistics/mosaic-ai-client/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from mosaicml import *\n",
    "from mosaicml.constants import MLModelFlavours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from tensordata import ops as utils_ops\n",
    "from tensordata import config\n",
    "# import gbiml\n",
    "import inspect\n",
    "import cloudpickle as cp\n",
    "\n",
    "from tensordata import label_map_util\n",
    "from tensordata import visualization_utils as vis_util\n",
    "from tensordata import detection_utils as detection_utils\n",
    "from werkzeug.datastructures import FileStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'tensordata/aptifyfull_3_.jpg'\n",
    "PATH_TO_FROZEN_GRAPH=r'tensordata/frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS=r'tensordata/label_map_table_detection.pbtxt'\n",
    "NUM_CLASSES=config.num_labels\n",
    "scoring_path = r'tensordata/score.pkl'\n",
    "graph_path = r'tensordata/frozen_inference_graph.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frozen_inference_graph(path):\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "      od_graph_def = tf.GraphDef()\n",
    "      with tf.gfile.GFile(path, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "    return detection_graph\n",
    "\n",
    "def save_tf_model(graph,path):\n",
    "    with tf.gfile.GFile(path, \"wb\") as f:\n",
    "        f.write(graph.as_graph_def().SerializeToString())\n",
    "        print(\"Frozen Graph Saved to :\",path)\n",
    "            \n",
    "\n",
    "def save_scoring_func(scoring_func, path):\n",
    "    with open(path, 'wb') as out:\n",
    "        cp.dump(scoring_func, out)\n",
    "\n",
    "\n",
    "def load_scoring_func(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        scoring_func = cp.load(f)\n",
    "    return scoring_func\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "    '''\n",
    "    Returns a numpy array of the image\n",
    "\n",
    "    Args:\n",
    "    image     : PIL Image object\n",
    "    '''\n",
    "    if len(image.getbands())<3: image=image.convert('RGB')\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = load_frozen_inference_graph(graph_path)\n",
    "#print(detection_graph)\n",
    "#sf = load_scoring_func(scoring_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(path)\n",
    "image_np = load_image_into_numpy_array(image)\n",
    "image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "#sf(detection_graph,image_np_expanded,threshold=0.0)\n",
    "#image_np_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 1700, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_lst = image_np.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_np_arry = np.array(image_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 1700, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_np_arry.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pcadmin/Desktop/project/AILogistics/mosaic-ai-client/examples/tensordata/label_map_util.py:131: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reframe_box_masks_to_image_masks(box_masks, boxes, image_height,\n",
    "                                     image_width):\n",
    "  \"\"\"Transforms the box masks back to full image masks.\n",
    "\n",
    "  Embeds masks in bounding boxes of larger masks whose shapes correspond to\n",
    "  image shape.\n",
    "\n",
    "  Args:\n",
    "    box_masks: A tf.float32 tensor of size [num_masks, mask_height, mask_width].\n",
    "    boxes: A tf.float32 tensor of size [num_masks, 4] containing the box\n",
    "           corners. Row i contains [ymin, xmin, ymax, xmax] of the box\n",
    "           corresponding to mask i. Note that the box corners are in\n",
    "           normalized coordinates.\n",
    "    image_height: Image height. The output mask will have the same height as\n",
    "                  the image height.\n",
    "    image_width: Image width. The output mask will have the same width as the\n",
    "                 image width.\n",
    "\n",
    "  Returns:\n",
    "    A tf.float32 tensor of size [num_masks, image_height, image_width].\n",
    "  \"\"\"\n",
    "  # TODO(rathodv): Make this a public function.\n",
    "  def reframe_box_masks_to_image_masks_default():\n",
    "    \"\"\"The default function when there are more than 0 box masks.\"\"\"\n",
    "    def transform_boxes_relative_to_boxes(boxes, reference_boxes):\n",
    "      boxes = tf.reshape(boxes, [-1, 2, 2])\n",
    "      min_corner = tf.expand_dims(reference_boxes[:, 0:2], 1)\n",
    "      max_corner = tf.expand_dims(reference_boxes[:, 2:4], 1)\n",
    "      transformed_boxes = (boxes - min_corner) / (max_corner - min_corner)\n",
    "      return tf.reshape(transformed_boxes, [-1, 4])\n",
    "\n",
    "    box_masks_expanded = tf.expand_dims(box_masks, axis=3)\n",
    "    num_boxes = tf.shape(box_masks_expanded)[0]\n",
    "    unit_boxes = tf.concat(\n",
    "        [tf.zeros([num_boxes, 2]), tf.ones([num_boxes, 2])], axis=1)\n",
    "    reverse_boxes = transform_boxes_relative_to_boxes(unit_boxes, boxes)\n",
    "    return tf.image.crop_and_resize(\n",
    "        image=box_masks_expanded,\n",
    "        boxes=reverse_boxes,\n",
    "        box_ind=tf.range(num_boxes),\n",
    "        crop_size=[image_height, image_width],\n",
    "        extrapolation_value=0.0)\n",
    "  image_masks = tf.cond(\n",
    "      tf.shape(box_masks)[0] > 0,\n",
    "      reframe_box_masks_to_image_masks_default,\n",
    "      lambda: tf.zeros([0, image_height, image_width, 1], dtype=tf.float32))\n",
    "  return tf.squeeze(image_masks, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image, graph):\n",
    "    '''\n",
    "    Returns predictions with scores, bounding boxes, number of detections etc in a form of dictionary\n",
    "\n",
    "    Args:\n",
    "    image              : numpy array of size (height,width,3)\n",
    "    graph              : frozen inference graph\n",
    "    '''\n",
    "    with graph.as_default():\n",
    "      with tf.Session() as sess:\n",
    "        # Get handles to input and output tensors\n",
    "        ops = tf.get_default_graph().get_operations()\n",
    "        all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "        tensor_dict = {}\n",
    "        for key in [\n",
    "            'num_detections', 'detection_boxes', 'detection_scores',\n",
    "            'detection_classes', 'detection_masks'\n",
    "        ]:\n",
    "          tensor_name = key + ':0'\n",
    "          if tensor_name in all_tensor_names:\n",
    "            tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                tensor_name)\n",
    "        if 'detection_masks' in tensor_dict:\n",
    "          # The following processing is only for single image\n",
    "          detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "          detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "          # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "          real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "          detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "          detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "          detection_masks_reframed =reframe_box_masks_to_image_masks(\n",
    "              detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "          detection_masks_reframed = tf.cast(\n",
    "              tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "          # Follow the convention by adding back the batch dimension\n",
    "          tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "              detection_masks_reframed, 0)\n",
    "        image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "        # Run inference\n",
    "        output_dict = sess.run(tensor_dict,\n",
    "                               feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "        # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "        output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "        output_dict['detection_classes'] = output_dict[\n",
    "            'detection_classes'][0].astype(np.uint8)\n",
    "        output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "        output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "        if 'detection_masks' in output_dict:\n",
    "          output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict\n",
    "\n",
    "def get_iou(bb1, bb2):\n",
    "    \"\"\"\n",
    "    Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bb1 : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x1, y1) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "    bb2 : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x, y) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        in [0, 1]\n",
    "    \"\"\"\n",
    "    assert bb1['x1'] < bb1['x2']\n",
    "    assert bb1['y1'] < bb1['y2']\n",
    "    assert bb2['x1'] < bb2['x2']\n",
    "    assert bb2['y1'] < bb2['y2']\n",
    "\n",
    "    # determine the coordinates of the intersection rectangle\n",
    "    x_left = max(bb1['x1'], bb2['x1'])\n",
    "    y_top = max(bb1['y1'], bb2['y1'])\n",
    "    x_right = min(bb1['x2'], bb2['x2'])\n",
    "    y_bottom = min(bb1['y2'], bb2['y2'])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # The intersection of two axis-aligned bounding boxes is always an\n",
    "    # axis-aligned bounding box\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # compute the area of both AABBs\n",
    "    bb1_area = (bb1['x2'] - bb1['x1']) * (bb1['y2'] - bb1['y1'])\n",
    "    bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
    "    assert iou >= 0.0\n",
    "    assert iou <= 1.0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def score(detection_graph, request):\n",
    "    '''\n",
    "    It finds out the regions of interest from the images specified by image_loc parameter \n",
    "    Args:\n",
    "    image_loc          : either a string (single path) of a list of paths to input images\n",
    "    category_index     : category index dictionary to map class ids with class names\n",
    "    threshold          : minimum confidence level in order to consider prediction.\n",
    "                         Default=0.97\n",
    "    '''\n",
    "    global category_index\n",
    "    out_dir = None\n",
    "    threshold = .97\n",
    "    #image\n",
    "    file= FileStorage(request.files['file1'])\n",
    "    file.save(\"f2.jpg\")\n",
    "    image_req = Image.open(\"f2.jpg\")\n",
    "    image_req_np = load_image_into_numpy_array(image_req)\n",
    "    img = image_req_np\n",
    "    \n",
    "    # list\n",
    "    #import pdb; pdb.set_trace()\n",
    "    #file= FileStorage(request.files['file1'])\n",
    "    #file.save(\"f2.txt\")\n",
    "    #with open(\"f2.txt\",\"r\") as f:\n",
    "    #    image_req=f.read()\n",
    "    #img = np.asarray(image_req)\n",
    "    \n",
    "    # for payload\n",
    "    #req_data = request.json[\"payload\"]\n",
    "    #data_list = req_data\n",
    "    #img = np.asarray(data_list)\n",
    "    \n",
    "    # Process the images\n",
    "    output_dict = run_inference_for_single_image(img, detection_graph)\n",
    "\n",
    "    # Setting custom threshold for the predictions and extracting only the top prediction per class\n",
    "    output_dict['detection_scores']=np.where(output_dict['detection_scores']>threshold,\n",
    "                                             output_dict['detection_scores'],\n",
    "                                             0.0)\n",
    "    final_output = {}\n",
    "    boxes = output_dict['detection_boxes']\n",
    "    scores = output_dict['detection_scores']\n",
    "    classes = output_dict['detection_classes']\n",
    "\n",
    "    for box,score,cls in zip(boxes,scores,classes):\n",
    "        if score<0.5:\n",
    "            continue\n",
    "        cls = category_index[cls]['name']\n",
    "        if cls not in  final_output.keys():\n",
    "            final_output[cls]=[[box.tolist(),score]]\n",
    "        else:\n",
    "            final_output[cls].append([box.tolist(),score])\n",
    "\n",
    "    consumption_output =[]\n",
    "    for table in final_output['table']:\n",
    "        table_details = {}\n",
    "        table_details['coordinates'] = table[0]\n",
    "        table_details['confidence'] = table[1]\n",
    "        table_details['column'] = []\n",
    "        table_details['header'] = []\n",
    "        b1 = {}\n",
    "        b1['y1'], b1['x1'], b1['y2'], b1['x2'] = table[0]\n",
    "        for header in final_output['header']:\n",
    "            b2 = {}\n",
    "            b2['y1'], b2['x1'], b2['y2'], b2['x2'] = header[0]\n",
    "            if get_iou(b1,b2)>0.05:\n",
    "                out_header = {}\n",
    "                out_header['coordinates'] = header[0]\n",
    "                out_header['confidence'] = header[1]\n",
    "                table_details['header'].append(out_header)\n",
    "\n",
    "        for col in final_output['col']:\n",
    "            c1={}\n",
    "            col_out = {}\n",
    "            c1['y1'], c1['x1'], c1['y2'], c1['x2'] = col[0]\n",
    "            if get_iou(b1,c1)>0.05:\n",
    "                col_out['coordinates'] = col[0]\n",
    "                col_out['confidence'] = col[1]\n",
    "                table_details['column'].append(col_out)\n",
    "\n",
    "        consumption_output.append(table_details)\n",
    "\n",
    "    return str(consumption_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "#aptifyfull_3_.jpg\n",
    "req = requests.Request()\n",
    "req.files= {\"file1\" : open('/home/pcadmin/Desktop/project/AILogistics/mosaic-ai-client/examples/tensordata/aptifyfull_3_.jpg','rb')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'coordinates': [0.14163130521774292, 0.0346657820045948, 0.41912317276000977, 0.8786301612854004], 'confidence': 0.999982, 'column': [{'coordinates': [0.18253648281097412, 0.5956850647926331, 0.3958061635494232, 0.7382981777191162], 'confidence': 0.99999964}, {'coordinates': [0.19028232991695404, 0.30118775367736816, 0.3950778841972351, 0.4318418502807617], 'confidence': 0.9999995}, {'coordinates': [0.19890160858631134, 0.43660441040992737, 0.3951108753681183, 0.5779754519462585], 'confidence': 0.9999976}, {'coordinates': [0.19285368919372559, 0.7353692650794983, 0.3925941586494446, 0.8562930226325989], 'confidence': 0.9999839}, {'coordinates': [0.18872244656085968, 0.06222282722592354, 0.3907977044582367, 0.17917387187480927], 'confidence': 0.9999478}, {'coordinates': [0.20323966443538666, 0.1858462393283844, 0.38711562752723694, 0.2916997969150543], 'confidence': 0.9994253}], 'header': [{'coordinates': [0.12847056984901428, 0.04787783324718475, 0.20246031880378723, 0.8682383298873901], 'confidence': 0.9993111}]}, {'coordinates': [0.6927739381790161, 0.09269895404577255, 0.8593398332595825, 0.8057839274406433], 'confidence': 0.9997799, 'column': [{'coordinates': [0.7355067133903503, 0.26445651054382324, 0.8508705496788025, 0.38944190740585327], 'confidence': 0.9999974}, {'coordinates': [0.7337542176246643, 0.5233688354492188, 0.8471471667289734, 0.6721920967102051], 'confidence': 0.9999962}, {'coordinates': [0.7398115992546082, 0.3964751660823822, 0.8436290621757507, 0.5139291286468506], 'confidence': 0.999995}, {'coordinates': [0.7290970087051392, 0.11960790306329727, 0.8509469032287598, 0.24824605882167816], 'confidence': 0.9999908}, {'coordinates': [0.7365564107894897, 0.6693205833435059, 0.8461790084838867, 0.7923862934112549], 'confidence': 0.99983704}], 'header': []}, {'coordinates': [0.5114151835441589, 0.08222300559282303, 0.6774612665176392, 0.8235955238342285], 'confidence': 0.9983841, 'column': [{'coordinates': [0.5663125514984131, 0.39123934507369995, 0.6573846936225891, 0.5101928114891052], 'confidence': 0.99999464}, {'coordinates': [0.5535522103309631, 0.10742177814245224, 0.6517041325569153, 0.2379702627658844], 'confidence': 0.99997544}, {'coordinates': [0.5591406226158142, 0.5214018225669861, 0.6574651002883911, 0.6705296635627747], 'confidence': 0.99996996}, {'coordinates': [0.561053991317749, 0.2665601670742035, 0.6660912036895752, 0.3671845495700836], 'confidence': 0.9999622}, {'coordinates': [0.5656673312187195, 0.6671226620674133, 0.6599830985069275, 0.7830029726028442], 'confidence': 0.9994618}], 'header': [{'coordinates': [0.48730167746543884, 0.1007402092218399, 0.557146430015564, 0.77559894323349], 'confidence': 0.98910856}]}]\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(detection_graph,req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "ndarray = np.array([1, 2, 3])\n",
    "listing = ndarray.tolist()\n",
    "print(listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_by': 'akhil.lawrence',\n",
       " 'created_on': '2019-10-20T13:39:36+00:00',\n",
       " 'description': 'testing temnsorflow model',\n",
       " 'flavour': 'tensorflow',\n",
       " 'id': 'd2328cd9-2190-47f5-9340-c07f364fe706',\n",
       " 'init_script': '',\n",
       " 'last_modified_by': 'akhil.lawrence',\n",
       " 'last_modified_on': '2019-10-20T13:39:36+00:00',\n",
       " 'name': 'tensorflow_16',\n",
       " 'project_id': '1',\n",
       " 'versions': [{'created_by': 'akhil.lawrence',\n",
       "   'created_on': '2019-10-20T13:39:37+00:00',\n",
       "   'deployments': [],\n",
       "   'description': None,\n",
       "   'id': 'f366fd69-e644-4e3a-93b2-04116ac2e810',\n",
       "   'last_modified_by': 'akhil.lawrence',\n",
       "   'last_modified_on': '2019-10-20T13:39:44+00:00',\n",
       "   'metadata_info': None,\n",
       "   'ml_model_id': 'd2328cd9-2190-47f5-9340-c07f364fe706',\n",
       "   'object_url': 'd2328cd9-2190-47f5-9340-c07f364fe706/f366fd69-e644-4e3a-93b2-04116ac2e810/ml_model.tar.gz',\n",
       "   'profiling': [],\n",
       "   'schema': None}]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "register_model(detection_graph, score, \"tensorflow_16\", \"testing temnsorflow model\", MLModelFlavours.tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pcadmin/Desktop/project/AILogistics/mosaic-ai-client/env/lib/python3.6/site-packages/mosaic_utils/ai/flavours/tensorflow.py:17: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.framework.ops.Graph at 0x7fe1a77e36a0>,\n",
       " <mosaic_utils.ai.decorators.scoring_func at 0x7fe1a77e3f60>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model(\"d2328cd9-2190-47f5-9340-c07f364fe706\", \"f366fd69-e644-4e3a-93b2-04116ac2e810\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'./frozen_inference_graph.pb'\n",
    "def load_frozen_inference_graph(path):\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "      od_graph_def = tf.GraphDef()\n",
    "      with tf.gfile.GFile(path, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "    return detection_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=load_frozen_inference_graph(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x7f0601483a20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.framework.ops.Graph object at 0x7f0601483a20>\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
